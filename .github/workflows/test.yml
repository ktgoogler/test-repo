name: Validate Source of Truth CSV

on:
  pull_request:
    branches: [main]  # Or your main branch name

jobs:
  validate_csv:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"  # Or your preferred version

      - name: Install required libraries
        run: |
          python -m pip install --upgrade pip
          pip install pandas pydantic  # Install pandas and pydantic

      - name: Validate CSV contents
        run: |
          # Create a separate Python file
          echo > validate_csv.py <<EOF
          import pandas as pd
          import sys
          from pydantic import BaseModel, ValidationError, validator, Field, StringConstraints
          from typing import Optional, Set
          from ipaddress import IPv4Network, AddressValueError
          import enum

          # Helper Functions
          def coerce_splt_commas_rtn_set_strs(value: str) -> Optional[Set[str]]:
              """Helper: Splits comma-separated string, returns set of strings"""
              if not value:
                  return None
              return {s.strip() for s in value.split(',')}

          def coerce_empty_str_to_none(value: str) -> Optional[str]:
              """Helper: Coerces empty string to None"""
              if value == "":
                  return None
              return value

          def unique(value: str) -> str:
              return value

          def validate_ipv4_address(ip: str, is_mandatory: bool = True) -> str:
              if not ip and not is_mandatory:
                  return ip
              try:
                  # Parse the CIDR notation using ip_network
                  IPv4Network(ip, strict=False)
              except (AddressValueError, ValueError) as e:
                  raise ValueError(f"Invalid CIDR value: {ip}. Error: {e}")
              return ip

          # Define enums (if needed, based on allowed values)
          # Example:
          # class ZoneName(enum.StrEnum):
          #     US_WEST1_EDGE_MTV51 = "us-west1-edge-mtv51"
          #     US_WEST1_EDGE_MTV52 = "us-west1-edge-mtv52"
          #     US_WEST1_EDGE_MTV53 = "us-west1-edge-mtv53"
          #     US_WEST1_EDGE_MTV54 = "us-west1-edge-mtv54"


          class SourceOfTruthModel(BaseModel):
              """
              Source of Truth Model
              """
              store_id: str = Field(min_length=1, max_length=20)
              zone_name: str = Field(min_length=1, max_length=50) #Could be an Enum
              machine_project_id: str = Field(min_length=1, max_length=50)
              fleet_project_id: str = Field(min_length=1, max_length=50)
              cluster_name: str = Field(min_length=1, max_length=50)
              location: str = Field(min_length=1, max_length=50)
              node_count: int = Field(ge=0)
              cluster_ipv4_cidr: str = pydantic.AfterValidator(validate_ipv4_address)
              services_ipv4_cidr: str = pydantic.AfterValidator(validate_ipv4_address)
              external_load_balancer_ipv4_address_pools: str
              sync_repo: str = pydantic.StringConstraints(min_length=1, max_length=200) #Basic
              sync_branch: str = Field(min_length=1, max_length=50)
              sync_dir: str = Field(min_length=1, max_length=100)
              secrets_project_id: str = Field(min_length=1, max_length=50)
              git_token_secrets_manager_name: str = Field(min_length=1, max_length=50)
              cluster_version: str = Field(min_length=1, max_length=20)
              maintenance_window_start: Optional[str] = Field(default=None)
              maintenance_window_end: Optional[str] = Field(default=None)
              maintenance_window_recurrence: Optional[str] = Field(default=None, min_length=1, max_length=50)
              maintenance_exclusion_name_1: Optional[str]  = Field(default=None, min_length=1, max_length=50)
              maintenance_exclusion_start_1: Optional[str] = Field(default=None)
              maintenance_exclusion_end_1: Optional[str] = Field(default=None)
              subnet_vlans: str = Field(min_length=1)
              recreate_on_delete: bool

              @validator('external_load_balancer_ipv4_address_pools')
              def validate_ipv4_address_pool(cls, pool):
                  ranges = pool.split(",")
                  for r in ranges:
                      ips = r.split("-")
                      if len(ips) != 2:
                          raise ValueError(f"Invalid IP address pool format: {pool}")
                      ip_parts1 = ips[0].split(".")
                      ip_parts2 = ips[1].split(".")
                      if len(ip_parts1) != 4 or len(ip_parts2) != 4:
                          raise ValueError(f"Invalid IP address pool format: {pool}")
                      try:
                          for i in range(4):
                              octet1 = int(ip_parts1[i])
                              octet2 = int(ip_parts2[i])
                              if (
                                  octet1 < 0
                                  or octet1 > 255
                                  or octet2 < 0
                                  or octet2 > 255
                              ):
                                  raise ValueError(f"Invalid IP address in pool: {pool}")
                      except ValueError:
                          raise ValueError(f"Invalid IP address pool format: {pool}")
                  return pool
              @validator('sync_repo')
              def validate_url(cls, url):
                  if not url.startswith("https://"):  # Basic URL validation
                      raise ValueError(f"Invalid URL format: {url}")
                  return url

              @validator('maintenance_window_start', 'maintenance_window_end')
              def validate_maintenance_window_time(cls, value):
                  if value is None:
                    return None
                  try:
                      pd.to_datetime(value, format="%H:%M")
                  except ValueError:
                      raise ValueError(f"Invalid time format. Expected HH:MM: {value}")
                  return value

              @validator('maintenance_exclusion_start_1', 'maintenance_exclusion_end_1')
              def validate_maintenance_exclusion_date(cls, value):
                  if value is None:
                    return None
                  try:
                      pd.to_datetime(value, format="%Y-%m-%d")
                  except ValueError:
                      raise ValueError(f"Invalid date format. Expected %Y-%m-%d: {value}")
                  return value



          def validate_data(df):
              errors = []
              for index, row in df.iterrows():
                  try:
                      # Convert row to a dictionary, handle NaNs, and create a SourceOfTruthModel object
                      row_dict = {k: None if pd.isna(v) else v for k, v in row.to_dict().items()}
                      SourceOfTruthModel(**row_dict)  # Validate the row
                  except ValidationError as e:
                      errors.append(f"Error in row {index + 2}: {e}")  # +2 for header and 0-based index
              return errors

          # Load the CSV file
          csv_file = "cluster-intent-registry.csv"
          try:
              df = pd.read_csv(csv_file)
          except FileNotFoundError:
              print(f"Error: CSV file not found at {csv_file}")
              sys.exit(1)
          except pd.errors.EmptyDataError:
              print(f"Error: CSV file is empty")
              sys.exit(1)
          except Exception as e:
              print(f"Error reading CSV file: {e}")
              sys.exit(1)

          # Validate the header
          expected_columns = [
              "store_id","zone_name","machine_project_id","fleet_project_id","cluster_name","location","node_count",
              "cluster_ipv4_cidr","services_ipv4_cidr","external_load_balancer_ipv4_address_pools",
              "sync_repo","sync_branch","sync_dir","secrets_project_id","git_token_secrets_manager_name",
              "cluster_version","maintenance_window_start","maintenance_window_end","maintenance_window_recurrence",
              "maintenance_exclusion_name_1","maintenance_exclusion_start_1","maintenance_exclusion_end_1","subnet_vlans","recreate_on_delete"
          ]
          if list(df.columns) != expected_columns:
              print(
                  "Error: CSV header does not match expected format.  Expected:"
                  f" {expected_columns} Got: {list(df.columns)}"
              )
              sys.exit(1)

          # Validate the data
          errors = validate_data(df)

          if errors:
              print("CSV validation failed:")
              for error in errors:
                  print(f"  - {error}")
              sys.exit(1)  # Fail the workflow
          else:
              print("CSV validation successful!") # Added success message
          EOF
          python validate_csv.py
